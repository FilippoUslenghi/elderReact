{"cells":[{"cell_type":"markdown","metadata":{},"source":[" #Visualizzazione dati"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from pandas.core.frame import DataFrame\n","import seaborn as sns\n","import cv2\n","from mpl_toolkits.mplot3d import Axes3D\n","import re\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ## Visualizzazione delle features di 40 video presi casualmente"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creazione delle variabili comuni\n","\n","base_dir = 'C:\\\\Users\\\\us98\\\\PycharmProjects\\\\elderReactProject\\\\myProcessed\\\\'\n","videoList = os.listdir(base_dir)\n","small_videoList = videoList[::15][:-1]\n","columns = [col.replace(\" \", \"\") for col in pd.read_csv(base_dir + '50_50_4\\\\50_50_4.csv').columns]\n",""]},{"cell_type":"markdown","metadata":{},"source":[" #### Visualizzazione della confidence"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Confidence nel tempo per ogni video:\")\n","\n","fig, axes = plt.subplots(8, 5, figsize=(25, 20), sharey=True)\n","axes = axes.flatten()\n","\n","for i, videoName in enumerate(small_videoList):\n","    videoCsv = base_dir + videoName + '\\\\' + videoName + \".csv\"\n","    df = pd.read_csv(videoCsv)\n","    df.columns = columns\n","    \n","    df[['confidence']].plot(ax=axes[i], legend = False)\n","    axes[i].set(xlabel='Frame Number', ylabel=\"Confidence\")\n","\n","plt.yticks([x/10 for x in range(11)])\n","plt.tight_layout()\n","plt.show()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" #### Visualizzazione del gaze angle"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Gaze angle nel tempo per ogni video:\")\n","\n","fig, axes = plt.subplots(8, 5, figsize=(25, 20), sharey=True)\n","axes = axes.flatten()\n","\n","for i, videoName in enumerate(small_videoList):\n","    videoCsv = base_dir + videoName + '\\\\' + videoName + '.csv'\n","    df = pd.read_csv(videoCsv)\n","    df.columns = columns\n","\n","    df[['gaze_angle_x', 'gaze_angle_y']].plot(ax=axes[i], legend = False)\n","    axes[i].set(ylim=[-1.5, 1.5], xlabel='Frame Number', ylabel='Radians', title=videoName)\n","    axes[i].legend(['gaze_angle_x', 'gaze_angle_y'], loc='lower left')\n","\n","plt.tight_layout()\n","plt.show()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" #### Visualizzazione delle coordinate 3D del *gaze vector*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Coordinate del gaze vector nel tempo per ogni video:\")\n","\n","fig = plt.figure(figsize=(25, 10))\n","for i, videoName in enumerate(small_videoList):\n","    videoCsv = base_dir + videoName + '\\\\' + videoName + '.csv'\n","    df = pd.read_csv(videoCsv)\n","    df.columns = columns\n","\n","\n","    # Plot delle coordinate spaziali del gaze vector\n","    ax = fig.add_subplot(4, 10, i+1, projection='3d')\n","\n","    ax.plot(df.gaze_0_x, df.gaze_0_y, df.gaze_0_z, color='blue')\n","    ax.plot(df.gaze_1_x, df.gaze_1_y, df.gaze_1_z, color='red')\n","    ax.set_title(videoName)\n","    ax.set(xlabel='x', ylabel='y', zlabel='z', xticks=[], yticks=[], zticks=[])\n","    ax.legend(['Leftmost eye', 'Rightmost eye'], fontsize='xx-small')\n","\n","plt.tight_layout()\n","plt.show()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" #### Visualizzazione della media dei *face landmark* in 2D di ogni frame"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Media delle coordinate 2D dei face landmark per ogni frame:\")\n","\n","x_regex_pat = re.compile(r'^x_[0-9]+$')\n","y_regex_pat = re.compile(r'^y_[0-9]+$')\n","\n","fig, axes = plt.subplots(8, 5, figsize=(15, 15), sharex=True, sharey=True)\n","axes = axes.flatten()\n","\n","for i, videoName in enumerate(small_videoList):\n","    videoCsv = base_dir + videoName + '\\\\' + videoName + '.csv'\n","    df = pd.read_csv(videoCsv)\n","    df.columns = columns\n","\n","    x_locs = df.columns[df.columns.str.contains(x_regex_pat)]\n","    y_locs = df.columns[df.columns.str.contains(y_regex_pat)]\n","\n","\n","    palette = sns.color_palette()\n","    avg_face_df = pd.DataFrame({'x_locs': df[x_locs].mean(axis=1), 'y_locs': df[y_locs].mean(axis=1)})\n","    sns.scatterplot(x='x_locs', y='y_locs', data=avg_face_df, marker='+', ax=axes[i])\n","    axes[i].set(xlim=[0, 1920], ylim=[1080, 0], title=videoName)\n","\n","plt.tight_layout()\n","plt.show()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" #### Visualizzazione della media dei *face landmark* in 2D di ogni frame"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Media delle coordinate 3D dei face landmark per ogni frame:\")\n","\n","X_regex_pat = re.compile(r'^X_[0-9]+$')\n","Y_regex_pat = re.compile(r'^Y_[0-9]+$')\n","Z_regex_pat = re.compile(r'^Z_[0-9]+$')\n","\n","fig = plt.figure(figsize=(25, 10))\n","for i, videoName in enumerate(small_videoList):\n","    videoCsv = base_dir + videoName + '\\\\' + videoName + '.csv'\n","    df = pd.read_csv(videoCsv)\n","    df.columns = columns\n","\n","    X_locs = df.columns[df.columns.str.contains(X_regex_pat)]\n","    Y_locs = df.columns[df.columns.str.contains(Y_regex_pat)]\n","    Z_locs = df.columns[df.columns.str.contains(Z_regex_pat)]\n","\n","    df_locs = pd.DataFrame({'X_locs': df[X_locs].mean(axis=1), 'Y_locs': df[Y_locs].mean(axis=1), 'Z_locs': df[Z_locs].mean(axis=1)})\n","\n","    # Plot delle coordinate spaziali del gaze vector\n","    ax = fig.add_subplot(4, 10, i+1, projection='3d')\n","\n","    ax.scatter(df_locs.X_locs, df_locs.Y_locs, df_locs.Z_locs, marker='+')\n","    ax.set_title(videoName)\n","    ax.set(xlabel='x', ylabel='y', zlabel='z', xticks=[], yticks=[], zticks=[])\n","\n","plt.tight_layout()\n","plt.show()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" #### Visualizzazione delle coordinate della *head pose location* di ogni frame"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Coordinate della head pose location di ogni frame:\")\n","\n","fig = plt.figure(figsize=(25, 10))\n","for i, videoName in enumerate(small_videoList):\n","    videoCsv = base_dir + videoName + '\\\\' + videoName + '.csv'\n","    df = pd.read_csv(videoCsv)\n","    df.columns = columns\n","\n","    # Plot delle coordinate spaziali del gaze vector\n","    ax = fig.add_subplot(4, 10, i+1, projection='3d')\n","\n","    ax.scatter(df.pose_Tx, df.pose_Ty, df.pose_Tz, marker='+')\n","    ax.set_title(videoName)\n","    ax.set(xlabel='x', ylabel='y', zlabel='z', xticks=[], yticks=[], zticks=[])\n",""]},{"cell_type":"markdown","metadata":{},"source":[" #### Visualizzazione della *head pose rotation* nel tempo per ogni video"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Head pose rotation nel tempo per ogni video:\")\n","\n","fig, axes = plt.subplots(8, 5, figsize=(25, 20), sharey=True)\n","axes = axes.flatten()\n","\n","for i, videoName in enumerate(small_videoList):\n","    videoCsv = base_dir + videoName + '\\\\' + videoName + '.csv'\n","    df = pd.read_csv(videoCsv)\n","    df.columns = columns\n","\n","    df[['pose_Rx', 'pose_Ry', 'pose_Rz']].plot(ax=axes[i], legend = False)\n","    axes[i].set(ylim=[-1.5, 1.5], xlabel='Frame Number', ylabel='Radians', title=videoName)\n","    axes[i].legend(['pose_Rx', 'pose_Ry', 'pose_Rz'], loc='lower left')\n","\n","plt.tight_layout()\n","plt.show()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" #### Visualizzazione dell'area contenuta dal contorno del volto, nel tempo, per ogni video"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def polyArea(x,y):\n","    return 0.5*np.abs(np.dot(x,np.roll(y,1))-np.dot(y,np.roll(x,1)))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Visualizzazione dell'area del volto per frame:\")\n","\n","# Per costruire l'area del volto le coordinate devono seguire questo pattern -> [x_0,...,x_16,x_26,...,x_17]\n","# ----------------------------------------------------------------------------- [y_0,...,y_16,y_26,...,y_17]\n","face_coordinates_pattern_x = ['x_' + str(x) for x in range(17)] + ['x_' + str(x) for x in range(17, 27)][::-1]\n","face_coordinates_pattern_y = ['y_' + str(y) for y in range(17)] + ['y_' + str(y) for y in range(17, 27)][::-1]\n","\n","fig, axes = plt.subplots(8, 5, figsize=(25, 15))\n","axes = axes.flatten()\n","\n","for i, videoName in enumerate(small_videoList):\n","    videoCsv = base_dir + videoName + '\\\\' + videoName + '.csv'\n","    df = pd.read_csv(videoCsv)\n","    df.columns = columns\n","\n","    # Face\n","    face_x_points_df = df[face_coordinates_pattern_x]\n","    face_y_points_df = df[face_coordinates_pattern_y]\n","    face_area_for_all_frames = np.zeros(shape=len(df))\n","\n","    for j in range(len(df)):\n","\n","        # Face\n","        face_x_points = face_x_points_df.iloc[j].to_numpy()\n","        face_y_points = face_y_points_df.iloc[j].to_numpy()\n","        face_area_frame_j = polyArea(face_x_points, face_y_points)\n","        face_area_for_all_frames[j] = face_area_frame_j\n","\n","    face_area_df = pd.DataFrame({'frame': df.frame, 'face_area': face_area_for_all_frames})\n","    palette = sns.color_palette()\n","    sns.lineplot(x='frame', y='face_area', data=face_area_df, ax=axes[i])\n","    axes[i].set(xlabel='Frame', ylabel='Area', title=videoName)\n","\n","plt.tight_layout()\n","plt.show()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" #### Visualizzazione dell'area contenuta dal contorno della bocca, nel tempo, per ogni video"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Visualizzazione dell'area della bocca per frame:\")\n","\n","# Per costruire l'area della bocca le coordinate devono seguire questo pattern -> [x_48,...,x_59]\n","# ------------------------------------------------------------------------------- [y_46,...,y_59]\n","mouth_coordinates_pattern_x = ['x_' + str(x) for x in range(48,60)]\n","mouth_coordinates_pattern_y = ['y_' + str(y) for y in range(48,60)]\n","\n","fig, axes = plt.subplots(8, 5, figsize=(25, 15))\n","axes = axes.flatten()\n","\n","for i, videoName in enumerate(small_videoList):\n","    videoCsv = base_dir + videoName + '\\\\' + videoName + '.csv'\n","    df = pd.read_csv(videoCsv)\n","    df.columns = columns\n","\n","    # Mouth\n","    mouth_x_points_df = df[mouth_coordinates_pattern_x]\n","    mouth_y_points_df = df[mouth_coordinates_pattern_y]\n","    mouth_area_for_all_frames = np.zeros(shape=len(df))\n","    \n","    for j in range(len(df)):\n","\n","        # Mouth\n","        mouth_x_points = mouth_x_points_df.iloc[j].to_numpy()\n","        mouth_y_points = mouth_y_points_df.iloc[j].to_numpy()\n","        mouth_area_frame_j = polyArea(mouth_x_points, mouth_y_points)\n","        mouth_area_for_all_frames[j] = mouth_area_frame_j\n","\n","    mouth_area_df = pd.DataFrame({'frame': df.frame, 'mouth_area': mouth_area_for_all_frames})\n","    palette = sns.color_palette()\n","    sns.lineplot(x='frame', y='mouth_area', data=mouth_area_df, ax=axes[i])\n","    axes[i].set(xlabel='Frame', ylabel='Area', title=videoName)\n","\n","plt.tight_layout()\n","plt.show()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" #### Visualizzazione dell'area contenuta dal contorno degli occhi, nel tempo, per ogni video"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Visualizzazione dell'area degli occhi per frame:\")\n","\n","# Per costruire l'area degli occhi le coordinate devono seguire questo pattern -> [eye_lmk_x_8,...,eye_lmk_x_19]\n","# ------------------------------------------------------------------------------- [eye_lmk_y_8,...,eye_lmk_y_19]\n","eye1_coordinates_pattern_x = ['eye_lmk_x_' + str(x) for x in range(8,20)]\n","eye1_coordinates_pattern_y = ['eye_lmk_y_' + str(y) for y in range(8,20)]\n","eye2_coordinates_pattern_x = ['eye_lmk_x_' + str(x) for x in range(36,48)]\n","eye2_coordinates_pattern_y = ['eye_lmk_y_' + str(y) for y in range(36,48)]\n","\n","fig, axes = plt.subplots(8, 5, figsize=(25, 15))\n","axes = axes.flatten()\n","\n","for i, videoName in enumerate(small_videoList):\n","    videoCsv = base_dir + videoName + '\\\\' + videoName + '.csv'\n","    df = pd.read_csv(videoCsv)\n","    df.columns = columns\n","\n","    # Eye1\n","    eye1_x_points_df = df[eye1_coordinates_pattern_x]\n","    eye1_y_points_df = df[eye1_coordinates_pattern_y]\n","    eye1_area_for_all_frames = np.zeros(shape=len(df))\n","\n","    # Eye2\n","    eye2_x_points_df = df[eye2_coordinates_pattern_x]\n","    eye2_y_points_df = df[eye2_coordinates_pattern_y]\n","    eye2_area_for_all_frames = np.zeros(shape=len(df))\n","    \n","    for j in range(len(df)):\n","\n","        # Eye1\n","        eye1_x_points = eye1_x_points_df.iloc[j].to_numpy()\n","        eye1_y_points = eye1_y_points_df.iloc[j].to_numpy()\n","        eye1_area_frame_j = polyArea(eye1_x_points, eye1_y_points)\n","        eye1_area_for_all_frames[j] = eye1_area_frame_j\n","\n","        # Eye2\n","        eye2_x_points = eye2_x_points_df.iloc[j].to_numpy()\n","        eye2_y_points = eye2_y_points_df.iloc[j].to_numpy()\n","        eye2_area_frame_j = polyArea(eye2_x_points, eye2_y_points)\n","        eye2_area_for_all_frames[j] = eye2_area_frame_j\n","\n","    eyes_area_df = pd.DataFrame({'frame': df.frame, 'eye1_area': eye1_area_for_all_frames, 'eye2_area': eye2_area_for_all_frames})\n","    palette = sns.color_palette()\n","    sns.lineplot(x='frame', y='eye1_area', data=eyes_area_df, ax=axes[i])\n","    sns.lineplot(x='frame', y='eye2_area', data=eyes_area_df, ax=axes[i])\n","    axes[i].set(xlabel='Frame', ylabel='Area', title=videoName)\n","    axes[i].legend(['Eye_1 area', 'Eye_2 area'], loc='lower left')\n","\n","plt.tight_layout()\n","plt.show()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" #### Visualizzazione dell'intensità delle *action unit*, nel tempo, per un video preso casualmente."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import random as rd\n","randVideoName = videoList[rd.randint(0, len(videoList))]\n","randVideoCsv = base_dir + randVideoName + '\\\\' + randVideoName + '.csv'\n","df = pd.read_csv(randVideoCsv)\n","df.columns = columns\n","# Plot all Action Unit time series. \n","au_regex_pat = re.compile(r'^AU[0-9]+_r$')\n","au_columns = df.columns[df.columns.str.contains(au_regex_pat)]\n","fig,axes = plt.subplots(6, 3, figsize=(10,12), sharex=True, sharey=True)\n","axes = axes.flatten()\n","for au_ix, au_col in enumerate(au_columns):\n","    sns.lineplot(x='frame', y=au_col, hue='face_id', data=df, ax=axes[au_ix])\n","    axes[au_ix].set(title=au_col, ylabel='Intensity')\n","    axes[au_ix].legend(loc=5)\n","plt.suptitle(randVideoName, y=1.02)\n","plt.tight_layout()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}